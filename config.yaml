llm:
  provider: openai
  model: gpt-4o-mini
  temperature: 0.1
  max_tokens: 4096

debug: true
log_level: DEBUG 